{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f45375-0ab2-4a24-8959-e4bb926e9720",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "from IPython.display import display, clear_output\n",
    "import os\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r'C:\\...\\Plot_Extract_Data+Estimated_MH.csv' #Path to file with training data\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter the data if necessary\n",
    "excluded_values = [1846]\n",
    "data_filtered = data[~data['UniqueID'].isin(excluded_values)]\n",
    "#data_filtered = data\n",
    "\n",
    "# Define predictor variables and the target variable\n",
    "predictors = ['B2_May', 'B3_May', 'B4_May', 'B5_May', 'B6_May', 'B7_May', 'B8_May', 'B8A_May', 'B11_May', 'B12_May',\n",
    "    'LAI_May', 'FCOVER_May', 'FAPAR_May', 'CAB_May', 'CWC_May',\n",
    "    'DVI_May', 'EVI_May', 'EVI2_May', 'GNDVI_May', 'GRVI_May', 'IRECI_May', 'MCARI_May', 'MSAVI_May', 'NBR_May', 'NBR2_May', \n",
    "    'NDI45_May', 'NDII_May', 'NDRE1_May', 'NDVI_May', 'NDVI2_May', 'NDVIRE_May', 'OSAVI_May', 'PSSRa_May', 'RERVI_May', 'CIre_May', \n",
    "    'RERDVI_May', 'RDVI_May', 'SAVI_May', 'STVI1_May', 'STVI2_May', 'STVI3_May', 'TCARI_May',\n",
    "    'NDRE2_May', 'RVI_May',\n",
    "    \n",
    "    'B2_Jun', 'B3_Jun', 'B4_Jun', 'B5_Jun', 'B6_Jun', 'B7_Jun', 'B8_Jun', 'B8A_Jun', 'B11_Jun', 'B12_Jun',\n",
    "    'LAI_Jun', 'FCOVER_Jun', 'FAPAR_Jun', 'CAB_Jun', 'CWC_Jun',\n",
    "    'DVI_Jun', 'EVI_Jun', 'EVI2_Jun', 'GNDVI_Jun', 'GRVI_Jun', 'IRECI_Jun', 'MCARI_Jun', 'MSAVI_Jun', 'NBR_Jun', 'NBR2_Jun', \n",
    "    'NDI45_Jun', 'NDII_Jun', 'NDRE1_Jun', 'NDVI_Jun', 'NDVI2_Jun', 'NDVIRE_Jun', 'OSAVI_Jun', 'PSSRa_Jun', 'RERVI_Jun', 'CIre_Jun', \n",
    "    'RERDVI_Jun', 'RDVI_Jun', 'SAVI_Jun', 'STVI1_Jun', 'STVI2_Jun', 'STVI3_Jun', 'TCARI_Jun',\n",
    "    'NDRE2_Jun', 'RVI_Jun',\n",
    "    \n",
    "    'B2_Jul', 'B3_Jul', 'B4_Jul', 'B5_Jul', 'B6_Jul', 'B7_Jul', 'B8_Jul', 'B8A_Jul', 'B11_Jul', 'B12_Jul',\n",
    "    'LAI_Jul', 'FCOVER_Jul', 'FAPAR_Jul', 'CAB_Jul', 'CWC_Jul',\n",
    "    'DVI_Jul', 'EVI_Jul', 'EVI2_Jul', 'GNDVI_Jul', 'GRVI_Jul', 'IRECI_Jul', 'MCARI_Jul', 'MSAVI_Jul', 'NBR_Jul', 'NBR2_Jul', \n",
    "    'NDI45_Jul', 'NDII_Jul', 'NDRE1_Jul', 'NDVI_Jul', 'NDVI2_Jul', 'NDVIRE_Jul', 'OSAVI_Jul', 'PSSRa_Jul', 'RERVI_Jul', 'CIre_Jul', \n",
    "    'RERDVI_Jul', 'RDVI_Jul', 'SAVI_Jul', 'STVI1_Jul', 'STVI2_Jul', 'STVI3_Jul', 'TCARI_Jul',\n",
    "    'NDRE2_Jul', 'RVI_Jul',\n",
    "    \n",
    "    'B2_Aug', 'B3_Aug', 'B4_Aug', 'B5_Aug', 'B6_Aug', 'B7_Aug', 'B8_Aug', 'B8A_Aug', 'B11_Aug', 'B12_Aug',\n",
    "    'LAI_Aug', 'FCOVER_Aug', 'FAPAR_Aug', 'CAB_Aug', 'CWC_Aug',\n",
    "    'DVI_Aug', 'EVI_Aug', 'EVI2_Aug', 'GNDVI_Aug', 'GRVI_Aug', 'IRECI_Aug', 'MCARI_Aug', 'MSAVI_Aug', 'NBR_Aug', 'NBR2_Aug', \n",
    "    'NDI45_Aug', 'NDII_Aug', 'NDRE1_Aug', 'NDVI_Aug', 'NDVI2_Aug', 'NDVIRE_Aug', 'OSAVI_Aug', 'PSSRa_Aug', 'RERVI_Aug', 'CIre_Aug', \n",
    "    'RERDVI_Aug', 'RDVI_Aug', 'SAVI_Aug', 'STVI1_Aug', 'STVI2_Aug', 'STVI3_Aug', 'TCARI_Aug',\n",
    "    'NDRE2_Aug', 'RVI_Aug',\n",
    "    \n",
    "    'B2_Sep', 'B3_Sep', 'B4_Sep', 'B5_Sep', 'B6_Sep', 'B7_Sep', 'B8_Sep', 'B8A_Sep', 'B11_Sep', 'B12_Sep',\n",
    "    'LAI_Sep', 'FCOVER_Sep', 'FAPAR_Sep', 'CAB_Sep', 'CWC_Sep',\n",
    "    'DVI_Sep', 'EVI_Sep', 'EVI2_Sep', 'GNDVI_Sep', 'GRVI_Sep', 'IRECI_Sep', 'MCARI_Sep', 'MSAVI_Sep', 'NBR_Sep', 'NBR2_Sep', \n",
    "    'NDI45_Sep', 'NDII_Sep', 'NDRE1_Sep', 'NDVI_Sep', 'NDVI2_Sep', 'NDVIRE_Sep', 'OSAVI_Sep', 'PSSRa_Sep', 'RERVI_Sep', 'CIre_Sep', \n",
    "    'RERDVI_Sep', 'RDVI_Sep', 'SAVI_Sep', 'STVI1_Sep', 'STVI2_Sep', 'STVI3_Sep', 'TCARI_Sep',\n",
    "    'NDRE2_Sep', 'RVI_Sep',\n",
    "    \n",
    "    'VV_Jan', 'VH_Jan', 'VVVH_ratio_Jan', 'sarRDI_Jan', 'sarNDI_Jan', 'sarSDI_Jan', \n",
    "              'sarSAI_Jan', 'sarMI_Jan', 'sarRI1_Jan', 'sarRI2_Jan', 'sarSqDI_Jan',\n",
    "              'GLCM_VV_asm_Jan', 'GLCM_VV_contrast_Jan', 'GLCM_VV_corr_Jan', 'GLCM_VV_var_Jan', 'GLCM_VV_idm_Jan', \n",
    "              'GLCM_VV_savg_Jan', 'GLCM_VV_svar_Jan', 'GLCM_VV_sent_Jan', 'GLCM_VV_ent_Jan', 'GLCM_VV_dvar_Jan', \n",
    "              'GLCM_VV_dent_Jan', 'GLCM_VV_diss_Jan', 'GLCM_VV_shade_Jan',\n",
    "              'GLCM_VH_asm_Jan', 'GLCM_VH_contrast_Jan', 'GLCM_VH_corr_Jan', 'GLCM_VH_var_Jan', 'GLCM_VH_idm_Jan', \n",
    "              'GLCM_VH_savg_Jan', 'GLCM_VH_svar_Jan', 'GLCM_VH_sent_Jan', 'GLCM_VH_ent_Jan', 'GLCM_VH_dvar_Jan', \n",
    "              'GLCM_VH_dent_Jan', 'GLCM_VH_diss_Jan', 'GLCM_VH_shade_Jan',\n",
    "              \n",
    "              'VV_Feb', 'VH_Feb', 'VVVH_ratio_Feb', 'sarRDI_Feb', 'sarNDI_Feb', 'sarSDI_Feb', \n",
    "              'sarSAI_Feb', 'sarMI_Feb', 'sarRI1_Feb', 'sarRI2_Feb', 'sarSqDI_Feb',\n",
    "              'GLCM_VV_asm_Feb', 'GLCM_VV_contrast_Feb', 'GLCM_VV_corr_Feb', 'GLCM_VV_var_Feb', 'GLCM_VV_idm_Feb', \n",
    "              'GLCM_VV_savg_Feb', 'GLCM_VV_svar_Feb', 'GLCM_VV_sent_Feb', 'GLCM_VV_ent_Feb', 'GLCM_VV_dvar_Feb', \n",
    "              'GLCM_VV_dent_Feb', 'GLCM_VV_diss_Feb', 'GLCM_VV_shade_Feb',\n",
    "              'GLCM_VH_asm_Feb', 'GLCM_VH_contrast_Feb', 'GLCM_VH_corr_Feb', 'GLCM_VH_var_Feb', 'GLCM_VH_idm_Feb', \n",
    "              'GLCM_VH_savg_Feb', 'GLCM_VH_svar_Feb', 'GLCM_VH_sent_Feb', 'GLCM_VH_ent_Feb', 'GLCM_VH_dvar_Feb', \n",
    "              'GLCM_VH_dent_Feb', 'GLCM_VH_diss_Feb', 'GLCM_VH_shade_Feb',\n",
    "              \n",
    "              'VV_Mar', 'VH_Mar', 'VVVH_ratio_Mar', 'sarRDI_Mar', 'sarNDI_Mar', 'sarSDI_Mar', \n",
    "              'sarSAI_Mar', 'sarMI_Mar', 'sarRI1_Mar', 'sarRI2_Mar', 'sarSqDI_Mar',\n",
    "              'GLCM_VV_asm_Mar', 'GLCM_VV_contrast_Mar', 'GLCM_VV_corr_Mar', 'GLCM_VV_var_Mar', 'GLCM_VV_idm_Mar', \n",
    "              'GLCM_VV_savg_Mar', 'GLCM_VV_svar_Mar', 'GLCM_VV_sent_Mar', 'GLCM_VV_ent_Mar', 'GLCM_VV_dvar_Mar', \n",
    "              'GLCM_VV_dent_Mar', 'GLCM_VV_diss_Mar', 'GLCM_VV_shade_Mar',\n",
    "              'GLCM_VH_asm_Mar', 'GLCM_VH_contrast_Mar', 'GLCM_VH_corr_Mar', 'GLCM_VH_var_Mar', 'GLCM_VH_idm_Mar', \n",
    "              'GLCM_VH_savg_Mar', 'GLCM_VH_svar_Mar', 'GLCM_VH_sent_Mar', 'GLCM_VH_ent_Mar', 'GLCM_VH_dvar_Mar', \n",
    "              'GLCM_VH_dent_Mar', 'GLCM_VH_diss_Mar', 'GLCM_VH_shade_Mar',\n",
    "              \n",
    "              'VV_Apr', 'VH_Apr', 'VVVH_ratio_Apr', 'sarRDI_Apr', 'sarNDI_Apr', 'sarSDI_Apr', \n",
    "              'sarSAI_Apr', 'sarMI_Apr', 'sarRI1_Apr', 'sarRI2_Apr', 'sarSqDI_Apr',\n",
    "              'GLCM_VV_asm_Apr', 'GLCM_VV_contrast_Apr', 'GLCM_VV_corr_Apr', 'GLCM_VV_var_Apr', 'GLCM_VV_idm_Apr', \n",
    "              'GLCM_VV_savg_Apr', 'GLCM_VV_svar_Apr', 'GLCM_VV_sent_Apr', 'GLCM_VV_ent_Apr', 'GLCM_VV_dvar_Apr', \n",
    "              'GLCM_VV_dent_Apr', 'GLCM_VV_diss_Apr', 'GLCM_VV_shade_Apr',\n",
    "              'GLCM_VH_asm_Apr', 'GLCM_VH_contrast_Apr', 'GLCM_VH_corr_Apr', 'GLCM_VH_var_Apr', 'GLCM_VH_idm_Apr', \n",
    "              'GLCM_VH_savg_Apr', 'GLCM_VH_svar_Apr', 'GLCM_VH_sent_Apr', 'GLCM_VH_ent_Apr', 'GLCM_VH_dvar_Apr', \n",
    "              'GLCM_VH_dent_Apr', 'GLCM_VH_diss_Apr', 'GLCM_VH_shade_Apr',\n",
    "              \n",
    "              'VV_May', 'VH_May', 'VVVH_ratio_May', 'sarRDI_May', 'sarNDI_May', 'sarSDI_May', \n",
    "              'sarSAI_May', 'sarMI_May', 'sarRI1_May', 'sarRI2_May', 'sarSqDI_May',\n",
    "              'GLCM_VV_asm_May', 'GLCM_VV_contrast_May', 'GLCM_VV_corr_May', 'GLCM_VV_var_May', 'GLCM_VV_idm_May', \n",
    "              'GLCM_VV_savg_May', 'GLCM_VV_svar_May', 'GLCM_VV_sent_May', 'GLCM_VV_ent_May', 'GLCM_VV_dvar_May', \n",
    "              'GLCM_VV_dent_May', 'GLCM_VV_diss_May', 'GLCM_VV_shade_May',\n",
    "              'GLCM_VH_asm_May', 'GLCM_VH_contrast_May', 'GLCM_VH_corr_May', 'GLCM_VH_var_May', 'GLCM_VH_idm_May', \n",
    "              'GLCM_VH_savg_May', 'GLCM_VH_svar_May', 'GLCM_VH_sent_May', 'GLCM_VH_ent_May', 'GLCM_VH_dvar_May', \n",
    "              'GLCM_VH_dent_May', 'GLCM_VH_diss_May', 'GLCM_VH_shade_May',\n",
    "              \n",
    "              'VV_Jun', 'VH_Jun', 'VVVH_ratio_Jun', 'sarRDI_Jun', 'sarNDI_Jun', 'sarSDI_Jun', \n",
    "              'sarSAI_Jun', 'sarMI_Jun', 'sarRI1_Jun', 'sarRI2_Jun', 'sarSqDI_Jun',\n",
    "              'GLCM_VV_asm_Jun', 'GLCM_VV_contrast_Jun', 'GLCM_VV_corr_Jun', 'GLCM_VV_var_Jun', 'GLCM_VV_idm_Jun', \n",
    "              'GLCM_VV_savg_Jun', 'GLCM_VV_svar_Jun', 'GLCM_VV_sent_Jun', 'GLCM_VV_ent_Jun', 'GLCM_VV_dvar_Jun', \n",
    "              'GLCM_VV_dent_Jun', 'GLCM_VV_diss_Jun', 'GLCM_VV_shade_Jun',\n",
    "              'GLCM_VH_asm_Jun', 'GLCM_VH_contrast_Jun', 'GLCM_VH_corr_Jun', 'GLCM_VH_var_Jun', 'GLCM_VH_idm_Jun', \n",
    "              'GLCM_VH_savg_Jun', 'GLCM_VH_svar_Jun', 'GLCM_VH_sent_Jun', 'GLCM_VH_ent_Jun', 'GLCM_VH_dvar_Jun', \n",
    "              'GLCM_VH_dent_Jun', 'GLCM_VH_diss_Jun', 'GLCM_VH_shade_Jun',\n",
    "              \n",
    "              'VV_Jul', 'VH_Jul', 'VVVH_ratio_Jul', 'sarRDI_Jul', 'sarNDI_Jul', 'sarSDI_Jul', \n",
    "              'sarSAI_Jul', 'sarMI_Jul', 'sarRI1_Jul', 'sarRI2_Jul', 'sarSqDI_Jul',\n",
    "              'GLCM_VV_asm_Jul', 'GLCM_VV_contrast_Jul', 'GLCM_VV_corr_Jul', 'GLCM_VV_var_Jul', 'GLCM_VV_idm_Jul', \n",
    "              'GLCM_VV_savg_Jul', 'GLCM_VV_svar_Jul', 'GLCM_VV_sent_Jul', 'GLCM_VV_ent_Jul', 'GLCM_VV_dvar_Jul', \n",
    "              'GLCM_VV_dent_Jul', 'GLCM_VV_diss_Jul', 'GLCM_VV_shade_Jul',\n",
    "              'GLCM_VH_asm_Jul', 'GLCM_VH_contrast_Jul', 'GLCM_VH_corr_Jul', 'GLCM_VH_var_Jul', 'GLCM_VH_idm_Jul', \n",
    "              'GLCM_VH_savg_Jul', 'GLCM_VH_svar_Jul', 'GLCM_VH_sent_Jul', 'GLCM_VH_ent_Jul', 'GLCM_VH_dvar_Jul', \n",
    "              'GLCM_VH_dent_Jul', 'GLCM_VH_diss_Jul', 'GLCM_VH_shade_Jul',\n",
    "              \n",
    "              'VV_Aug', 'VH_Aug', 'VVVH_ratio_Aug', 'sarRDI_Aug', 'sarNDI_Aug', 'sarSDI_Aug', \n",
    "              'sarSAI_Aug', 'sarMI_Aug', 'sarRI1_Aug', 'sarRI2_Aug', 'sarSqDI_Aug',\n",
    "              'GLCM_VV_asm_Aug', 'GLCM_VV_contrast_Aug', 'GLCM_VV_corr_Aug', 'GLCM_VV_var_Aug', 'GLCM_VV_idm_Aug', \n",
    "              'GLCM_VV_savg_Aug', 'GLCM_VV_svar_Aug', 'GLCM_VV_sent_Aug', 'GLCM_VV_ent_Aug', 'GLCM_VV_dvar_Aug', \n",
    "              'GLCM_VV_dent_Aug', 'GLCM_VV_diss_Aug', 'GLCM_VV_shade_Aug',\n",
    "              'GLCM_VH_asm_Aug', 'GLCM_VH_contrast_Aug', 'GLCM_VH_corr_Aug', 'GLCM_VH_var_Aug', 'GLCM_VH_idm_Aug', \n",
    "              'GLCM_VH_savg_Aug', 'GLCM_VH_svar_Aug', 'GLCM_VH_sent_Aug', 'GLCM_VH_ent_Aug', 'GLCM_VH_dvar_Aug', \n",
    "              'GLCM_VH_dent_Aug', 'GLCM_VH_diss_Aug', 'GLCM_VH_shade_Aug',\n",
    "              \n",
    "              'VV_Sep', 'VH_Sep', 'VVVH_ratio_Sep', 'sarRDI_Sep', 'sarNDI_Sep', 'sarSDI_Sep', \n",
    "              'sarSAI_Sep', 'sarMI_Sep', 'sarRI1_Sep', 'sarRI2_Sep', 'sarSqDI_Sep',\n",
    "              'GLCM_VV_asm_Sep', 'GLCM_VV_contrast_Sep', 'GLCM_VV_corr_Sep', 'GLCM_VV_var_Sep', 'GLCM_VV_idm_Sep', \n",
    "              'GLCM_VV_savg_Sep', 'GLCM_VV_svar_Sep', 'GLCM_VV_sent_Sep', 'GLCM_VV_ent_Sep', 'GLCM_VV_dvar_Sep', \n",
    "              'GLCM_VV_dent_Sep', 'GLCM_VV_diss_Sep', 'GLCM_VV_shade_Sep',\n",
    "              'GLCM_VH_asm_Sep', 'GLCM_VH_contrast_Sep', 'GLCM_VH_corr_Sep', 'GLCM_VH_var_Sep', 'GLCM_VH_idm_Sep', \n",
    "              'GLCM_VH_savg_Sep', 'GLCM_VH_svar_Sep', 'GLCM_VH_sent_Sep', 'GLCM_VH_ent_Sep', 'GLCM_VH_dvar_Sep', \n",
    "              'GLCM_VH_dent_Sep', 'GLCM_VH_diss_Sep', 'GLCM_VH_shade_Sep',\n",
    "              \n",
    "              'VV_Oct', 'VH_Oct', 'VVVH_ratio_Oct', 'sarRDI_Oct', 'sarNDI_Oct', 'sarSDI_Oct', \n",
    "              'sarSAI_Oct', 'sarMI_Oct', 'sarRI1_Oct', 'sarRI2_Oct', 'sarSqDI_Oct',\n",
    "              'GLCM_VV_asm_Oct', 'GLCM_VV_contrast_Oct', 'GLCM_VV_corr_Oct', 'GLCM_VV_var_Oct', 'GLCM_VV_idm_Oct', \n",
    "              'GLCM_VV_savg_Oct', 'GLCM_VV_svar_Oct', 'GLCM_VV_sent_Oct', 'GLCM_VV_ent_Oct', 'GLCM_VV_dvar_Oct', \n",
    "              'GLCM_VV_dent_Oct', 'GLCM_VV_diss_Oct', 'GLCM_VV_shade_Oct',\n",
    "              'GLCM_VH_asm_Oct', 'GLCM_VH_contrast_Oct', 'GLCM_VH_corr_Oct', 'GLCM_VH_var_Oct', 'GLCM_VH_idm_Oct', \n",
    "              'GLCM_VH_savg_Oct', 'GLCM_VH_svar_Oct', 'GLCM_VH_sent_Oct', 'GLCM_VH_ent_Oct', 'GLCM_VH_dvar_Oct', \n",
    "              'GLCM_VH_dent_Oct', 'GLCM_VH_diss_Oct', 'GLCM_VH_shade_Oct',\n",
    "              \n",
    "              'VV_Nov', 'VH_Nov', 'VVVH_ratio_Nov', 'sarRDI_Nov', 'sarNDI_Nov', 'sarSDI_Nov', \n",
    "              'sarSAI_Nov', 'sarMI_Nov', 'sarRI1_Nov', 'sarRI2_Nov', 'sarSqDI_Nov',\n",
    "              'GLCM_VV_asm_Nov', 'GLCM_VV_contrast_Nov', 'GLCM_VV_corr_Nov', 'GLCM_VV_var_Nov', 'GLCM_VV_idm_Nov', \n",
    "              'GLCM_VV_savg_Nov', 'GLCM_VV_svar_Nov', 'GLCM_VV_sent_Nov', 'GLCM_VV_ent_Nov', 'GLCM_VV_dvar_Nov', \n",
    "              'GLCM_VV_dent_Nov', 'GLCM_VV_diss_Nov', 'GLCM_VV_shade_Nov',\n",
    "              'GLCM_VH_asm_Nov', 'GLCM_VH_contrast_Nov', 'GLCM_VH_corr_Nov', 'GLCM_VH_var_Nov', 'GLCM_VH_idm_Nov', \n",
    "              'GLCM_VH_savg_Nov', 'GLCM_VH_svar_Nov', 'GLCM_VH_sent_Nov', 'GLCM_VH_ent_Nov', 'GLCM_VH_dvar_Nov', \n",
    "              'GLCM_VH_dent_Nov', 'GLCM_VH_diss_Nov', 'GLCM_VH_shade_Nov',\n",
    "              \n",
    "              'VV_Dec', 'VH_Dec', 'VVVH_ratio_Dec', 'sarRDI_Dec', 'sarNDI_Dec', 'sarSDI_Dec', \n",
    "              'sarSAI_Dec', 'sarMI_Dec', 'sarRI1_Dec', 'sarRI2_Dec', 'sarSqDI_Dec',\n",
    "              'GLCM_VV_asm_Dec', 'GLCM_VV_contrast_Dec', 'GLCM_VV_corr_Dec', 'GLCM_VV_var_Dec', 'GLCM_VV_idm_Dec', \n",
    "              'GLCM_VV_savg_Dec', 'GLCM_VV_svar_Dec', 'GLCM_VV_sent_Dec', 'GLCM_VV_ent_Dec', 'GLCM_VV_dvar_Dec', \n",
    "              'GLCM_VV_dent_Dec', 'GLCM_VV_diss_Dec', 'GLCM_VV_shade_Dec',\n",
    "              'GLCM_VH_asm_Dec', 'GLCM_VH_contrast_Dec', 'GLCM_VH_corr_Dec', 'GLCM_VH_var_Dec', 'GLCM_VH_idm_Dec', \n",
    "              'GLCM_VH_savg_Dec', 'GLCM_VH_svar_Dec', 'GLCM_VH_sent_Dec', 'GLCM_VH_ent_Dec', 'GLCM_VH_dvar_Dec', \n",
    "              'GLCM_VH_dent_Dec', 'GLCM_VH_diss_Dec', 'GLCM_VH_shade_Dec',\n",
    "\n",
    "                'DEM', 'slope', 'aspect',\n",
    "\n",
    "              #'Estimated_MH' \n",
    "    \n",
    "    ]  \n",
    "\n",
    "#Set target variable variable dependent on what is being estiamted\n",
    "#target = 'MeanHeight'        # Mean height (MH)\n",
    "target = 'Dw_All_Mg'        # Aboveground Biomass (AGB)\n",
    "\n",
    "# Display the shape of the original and filtered data to see how many outliers were removed\n",
    "print(f\"Original data shape: {data_filtered.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a0e4a4-28cb-4a83-9a23-ecc39f56bd30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Assuming 'data_filtered', 'predictors', and 'target' are defined\n",
    "current_predictors = predictors[:]\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "results_df = pd.DataFrame(columns=['Iteration', 'Number of Variables', 'Least Important Predictor', 'RMSE', 'R²', 'MAE', 'RMSE%'])\n",
    "iteration = 1\n",
    "\n",
    "best_rmse = np.inf\n",
    "best_r2 = None\n",
    "best_mae = None\n",
    "best_predictors = None\n",
    "\n",
    "# Calculate the average of observations for RMSE%\n",
    "average_observation = data_filtered[target].mean()\n",
    "\n",
    "# Begin the feature removal loop\n",
    "while len(current_predictors) > 1:\n",
    "    fold_importances = np.zeros(len(current_predictors))\n",
    "    fold_rmses, fold_r2s, fold_maes = [], [], []\n",
    "\n",
    "    for train_index, test_index in kf.split(data_filtered[current_predictors]):\n",
    "        X_train, X_test = data_filtered[current_predictors].iloc[train_index], data_filtered[current_predictors].iloc[test_index]\n",
    "        y_train, y_test = data_filtered[target].iloc[train_index], data_filtered[target].iloc[test_index]\n",
    "\n",
    "        rf = RandomForestRegressor(n_estimators=500, max_features='sqrt', random_state=7)\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        # Aggregate feature importances from each fold\n",
    "        fold_importances += rf.feature_importances_\n",
    "\n",
    "        # Evaluate model performance and collect metrics for the fold\n",
    "        predictions = rf.predict(X_test)\n",
    "        fold_rmses.append(np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "        fold_r2s.append(r2_score(y_test, predictions))\n",
    "        fold_maes.append(mean_absolute_error(y_test, predictions))\n",
    "\n",
    "   \n",
    "\n",
    "    average_rmse = round(np.mean(fold_rmses), 3)\n",
    "    rmse_percent = round((average_rmse / average_observation) * 100, 3)  # Calculate RMSE%\n",
    "    average_r2 = round(np.mean(fold_r2s), 3)\n",
    "    average_mae = round(np.mean(fold_maes), 3)\n",
    "\n",
    "    if average_rmse < best_rmse:\n",
    "        best_rmse, best_r2, best_mae, best_predictors = average_rmse, average_r2, average_mae, current_predictors[:]\n",
    "\n",
    "    average_importances = fold_importances / kf.n_splits\n",
    "    least_important_idx = np.argmin(average_importances)\n",
    "    least_important_feature = current_predictors.pop(least_important_idx)\n",
    "    \n",
    "    results_df.loc[iteration] = [iteration, len(current_predictors) + 1, least_important_feature, average_rmse, average_r2, average_mae, rmse_percent]\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # Set matplotlib to embed text as paths to preserve font appearance\n",
    "    plt.rcParams['svg.fonttype'] = 'path'\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "    font_path = 'C:/Windows/Fonts/cambria.ttc'  # Update the path as necessary\n",
    "    cambria_font = font_manager.FontProperties(fname=font_path)\n",
    "\n",
    "    ax1.set_facecolor('white')  # Set the axes background color\n",
    "    fig.patch.set_facecolor('white')  # Set the figure background color\n",
    "    \n",
    "    ax1.set_xlabel('Iteration', fontproperties=cambria_font)\n",
    "    ax1.set_ylabel('Average RMSE', color='forestgreen', fontproperties=cambria_font)\n",
    "    ax1.plot(results_df['Iteration'], results_df['RMSE'], marker='.', linestyle='-', color='forestgreen')\n",
    "    ax1.tick_params(axis='y', labelcolor='forestgreen')\n",
    "\n",
    "    # Fit a linear trendline to the RMSE data\n",
    "    coefficients_rmse = np.polyfit(results_df['Iteration'], results_df['RMSE'], 1)  # 1 indicates a linear model\n",
    "    polynomial_rmse = np.poly1d(coefficients_rmse)\n",
    "    # Generate y-values for the trendline over the range of x-values\n",
    "    trendline_rmse = polynomial_rmse(results_df['Iteration'])\n",
    "\n",
    "    # Plot the RMSE trendline\n",
    "    ax1.plot(results_df['Iteration'], trendline_rmse, label='RMSE Trendline', color='darkgreen', linestyle='--')\n",
    "\n",
    "    # Make the horizontal grid lines correspond to the left y-axis (RMSE)\n",
    "    ax1.grid(True, which='both', axis='y', color='grey', linestyle='-', linewidth=0.25)\n",
    "    ax1.set_axisbelow(True)\n",
    "\n",
    "    # Adding a second y-axis for R²\n",
    "    ax2 = ax1.twinx()  # Create a second y-axis that shares the same x-axis\n",
    "    ax2.set_ylabel('R^2', color='#994F00', fontproperties=cambria_font)  # Label for the second y-axis\n",
    "    ax2.plot(results_df['Iteration'], results_df['R²'], marker='x', linestyle='-', color='#994F00')  # Use 'R²'\n",
    "    ax2.tick_params(axis='y', labelcolor='#994F00')\n",
    "\n",
    "    # Fit a linear trendline to the R² data\n",
    "    coefficients_r2 = np.polyfit(results_df['Iteration'], results_df['R²'], 1)  # 1 indicates a linear model\n",
    "    polynomial_r2 = np.poly1d(coefficients_r2)\n",
    "    # Generate y-values for the trendline over the range of x-values\n",
    "    trendline_r2 = polynomial_r2(results_df['Iteration'])\n",
    "\n",
    "    # Plot the R² trendline\n",
    "    ax2.plot(results_df['Iteration'], trendline_r2, label='$R^2$ Trendline', color='brown', linestyle='--')\n",
    "\n",
    "    for label in (ax1.get_xticklabels() + ax1.get_yticklabels() + ax2.get_yticklabels()):\n",
    "        label.set_fontproperties(cambria_font)\n",
    "\n",
    "    plt.title('Average RMSE and R^2 by Iteration', fontproperties=cambria_font)\n",
    "    plt.subplots_adjust(top=0.85)  # Adjust layout to provide more space for the title\n",
    "\n",
    "    plt.show()\n",
    "    display(results_df)\n",
    "\n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9421b8d3-e6da-47f4-8eb6-15325d726142",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# After exiting the loop, save the final figure\n",
    "save_dir = r'C:\\...' #Set save directory\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Final plot for saving\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "ax1.set_facecolor('white')  # Set the axes background color\n",
    "fig.patch.set_facecolor('white')  # Set the figure background color\n",
    "ax1.set_xlabel('Iteration', fontproperties=cambria_font)\n",
    "ax1.set_ylabel('Average RMSE', color='forestgreen', fontproperties=cambria_font)\n",
    "ax1.plot(results_df['Iteration'], results_df['RMSE'], marker='.', linestyle='-', linewidth=0.5, color='forestgreen')\n",
    "ax1.tick_params(axis='y', labelcolor='forestgreen')\n",
    "\n",
    "# Add R² to the final plot as well\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('$R^2$', color='#994F00', fontproperties=cambria_font)\n",
    "ax2.plot(results_df['Iteration'], results_df['R²'], marker='x', linestyle='-', linewidth=0.5, color='#994F00')\n",
    "ax2.tick_params(axis='y', labelcolor='#994F00')\n",
    "\n",
    "for label in (ax1.get_xticklabels() + ax1.get_yticklabels() + ax2.get_yticklabels()):\n",
    "    label.set_fontproperties(cambria_font)\n",
    "\n",
    "plt.title('Average RMSE and $R^2$ by Iteration', fontproperties=cambria_font)\n",
    "ax1.grid(True, which='both', axis='y', color='grey', linestyle='-', linewidth=0.25)\n",
    "ax1.set_axisbelow(True)\n",
    "plt.subplots_adjust(top=0.85)\n",
    "\n",
    "# Save the final figure\n",
    "plt.savefig(os.path.join(save_dir, 'RF_optimisation_.svg'))   #Set appropriate name\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"Lowest RMSE: {best_rmse:.4f}, RMSE%: {(best_rmse / average_observation) * 100:.4f}%\")\n",
    "print(f\"Corresponding R²: {best_r2:.4f}, MAE: {best_mae:.4f}\")\n",
    "print(f\"Best set of predictors: {best_predictors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e2a632-402b-40cc-aa76-3625c5aaefb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'data_filtered', 'best_predictors', and 'target' are defined\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "\n",
    "# Define the range of hyperparameters to test\n",
    "max_features_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  \n",
    "n_estimators_range = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "results_list = []\n",
    "\n",
    "# Loop through the range of hyperparameters\n",
    "for max_features in max_features_range:\n",
    "    for n_estimators in n_estimators_range:\n",
    "        fold_rmses = []  # To store the RMSE of each fold\n",
    "\n",
    "        for train_index, test_index in kf.split(data_filtered[best_predictors]):\n",
    "            X_train, X_test = data_filtered.iloc[train_index][best_predictors], data_filtered.iloc[test_index][best_predictors]\n",
    "            y_train, y_test = data_filtered.iloc[train_index][target], data_filtered.iloc[test_index][target]\n",
    "\n",
    "            # Initialize the model with current hyperparameters\n",
    "            rf = RandomForestRegressor(n_estimators=n_estimators, max_features=max_features, random_state=7)\n",
    "            rf.fit(X_train, y_train)\n",
    "\n",
    "            # Make predictions and calculate RMSE for the current fold\n",
    "            predictions = rf.predict(X_test)\n",
    "            fold_rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "            fold_rmses.append(fold_rmse)\n",
    "\n",
    "        # Calculate the average RMSE across all folds for the current set of hyperparameters\n",
    "        average_rmse = np.mean(fold_rmses)\n",
    "\n",
    "        # Append the results to the list\n",
    "        results_list.append({'Max Features': max_features, 'N Estimators': n_estimators, 'Average RMSE': average_rmse})\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "hyperparameter_results = pd.DataFrame(results_list)\n",
    "\n",
    "# Identify the best hyperparameter combination\n",
    "best_hyperparameters = hyperparameter_results.loc[hyperparameter_results['Average RMSE'].idxmin()]\n",
    "print(f\"Best Hyperparameters: Max Features = {best_hyperparameters['Max Features']}, N Estimators = {best_hyperparameters['N Estimators']}\")\n",
    "print(f\"Lowest Average RMSE: {best_hyperparameters['Average RMSE']:.4f}\")\n",
    "\n",
    "print(hyperparameter_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb9b5fd-6ca6-477a-a6d5-a586d77dd0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and convert the best hyperparameters to integers\n",
    "best_max_features = int(best_hyperparameters['Max Features'])\n",
    "best_n_estimators = int(best_hyperparameters['N Estimators'])\n",
    "\n",
    "# Define the range of seeds\n",
    "seeds_range = range(1, 11)\n",
    "\n",
    "# Initialize lists to store the metrics for each seed\n",
    "all_rmses, all_r2s, all_maes = [], [], []\n",
    "\n",
    "# Initialize dictionary to store predictions for each test point across all seeds\n",
    "all_predictions = {}\n",
    "\n",
    "# Loop over each seed\n",
    "for seed in seeds_range:\n",
    "    fold_rmses, fold_r2s, fold_maes = [], [], []  # Lists to store the metrics for each fold\n",
    "\n",
    "    # Perform 5-fold cross-validation\n",
    "    for train_index, test_index in kf.split(data_filtered[best_predictors]):\n",
    "        X_train, X_test = data_filtered.iloc[train_index][best_predictors], data_filtered.iloc[test_index][best_predictors]\n",
    "        y_train, y_test = data_filtered.iloc[train_index][target], data_filtered.iloc[test_index][target]\n",
    "\n",
    "        # Initialize the model with the best hyperparameters and current seed\n",
    "        rf = RandomForestRegressor(n_estimators=best_n_estimators, max_features=best_max_features, random_state=seed)\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions for the current fold\n",
    "        predictions = rf.predict(X_test)\n",
    "\n",
    "        # Store predictions in the dictionary\n",
    "        for idx, test_idx in enumerate(test_index):\n",
    "            if test_idx not in all_predictions:\n",
    "                all_predictions[test_idx] = []\n",
    "            all_predictions[test_idx].append(predictions[idx])\n",
    "\n",
    "\n",
    "        # Calculate metrics\n",
    "        fold_rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "        fold_r2 = r2_score(y_test, predictions)\n",
    "        fold_mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "        # Append metrics to their respective lists\n",
    "        fold_rmses.append(fold_rmse)\n",
    "        fold_r2s.append(fold_r2)\n",
    "        fold_maes.append(fold_mae)\n",
    "\n",
    "    # Append averages of metrics to the all_* lists\n",
    "    all_rmses.append(np.mean(fold_rmses))\n",
    "    all_r2s.append(np.mean(fold_r2s))\n",
    "    all_maes.append(np.mean(fold_maes))\n",
    "\n",
    "# Calculate the overall average of the metrics across all seeds\n",
    "average_rmse = np.mean(all_rmses)\n",
    "average_r2 = np.mean(all_r2s)\n",
    "average_mae = np.mean(all_maes)\n",
    "average_rmse_percent = (average_rmse / data_filtered[target].mean()) * 100  # RMSE% calculation\n",
    "\n",
    "# Output the results\n",
    "print(f\"Average RMSE across seeds: {average_rmse:.3f}\")\n",
    "print(f\"Average RMSE% across seeds: {average_rmse_percent:.2f}%\")\n",
    "print(f\"Average R² across seeds: {average_r2:.3f}\")\n",
    "print(f\"Average MAE across seeds: {average_mae:.3f}\")\n",
    "\n",
    "# Average predictions for each data point and prepare for plotting\n",
    "final_predictions = [np.mean(preds) for preds in all_predictions.values()]\n",
    "true_values = [data_filtered.iloc[idx][target] for idx in all_predictions.keys()]\n",
    "\n",
    "# Path to Cambria font\n",
    "font_path = 'C:/Windows/Fonts/cambria.ttc'\n",
    "cambria_font = font_manager.FontProperties(fname=font_path)\n",
    "\n",
    "# Update matplotlib's font settings to Cambria\n",
    "plt.rcParams.update({'font.family': 'Cambria', 'svg.fonttype': 'path'})\n",
    "\n",
    "# Create the figure and axis objects\n",
    "fig, ax1 = plt.subplots(figsize=(5, 5))\n",
    "fig.subplots_adjust(bottom=0.2)  # Adjust the bottom margin\n",
    "\n",
    "\n",
    "# Plotting predicted vs. observed values in dark green\n",
    "ax1.scatter(true_values, final_predictions, alpha=0.5, color='darkgreen', label='Predictions', zorder=3)\n",
    "\n",
    "# Adding a 45-degree line in 70% gray and making it thinner, extending up to 500\n",
    "ax1.plot([-1, 501], [-1, 501], color='#B3B3B3', linestyle='--', lw=1, label='1:1 Line')\n",
    "\n",
    "# Calculate and plot the trendline\n",
    "z = np.polyfit(true_values, final_predictions, 1)\n",
    "p = np.poly1d(z)\n",
    "ax1.plot(true_values, p(true_values), label=\"Trendline\", color='darkgreen', linestyle='-', lw=1)\n",
    "\n",
    "# Setting the title and labels with Cambria font\n",
    "ax1.set_xlabel('Observed AGB (Mg.ha-1)', fontproperties=cambria_font, size=11)\n",
    "ax1.set_ylabel('Estimated AGB (Mg.ha-1)', fontproperties=cambria_font, size=11)\n",
    "\n",
    "# Adjust the axis limits and tick marks to match the data range\n",
    "ax1.set_xlim(-1, 451)\n",
    "ax1.set_ylim(-1, 451)\n",
    "ax1.set_xticks(range(0, 451, 50))\n",
    "ax1.set_yticks(range(0, 451, 50))\n",
    "\n",
    "# Ensure a 1:1 aspect ratio\n",
    "ax1.set_aspect('equal', adjustable='box')\n",
    "\n",
    "# Manually setting the average R^2 value to 0.522 for display\n",
    "plt.annotate(f'R² = {average_r2:.3f}', xy=(0.05, 0.95), xycoords='axes fraction', fontproperties=cambria_font)\n",
    "plt.annotate(f'(b)', xy=(0.50, -0.20), xycoords='axes fraction', fontproperties=cambria_font, size=14)\n",
    "\n",
    "# Save the plot as an SVG file before showing it\n",
    "plot_save_path = r'C:\\...\\Scatterplot_RF_.svg' #Set directory and appropriate name\n",
    "plt.savefig(plot_save_path, format='svg')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7285ff9-b7e6-47c6-963a-18afab5218c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
