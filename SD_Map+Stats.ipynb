{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a457bdb6-e4ef-448f-be4b-9aceeb9491aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Load training data\n",
    "file_path = r'C:\\...\\Plot_Extract_Data+Estimated_MH.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Filter the data\n",
    "excluded_values = [1846]            \n",
    "df = df[~df['UniqueID'].isin(excluded_values)]\n",
    "\n",
    "# Define predictors and target variable\n",
    "predictors = [\n",
    "    'B3_Jul', 'B3_Jun', 'B5_Jul', 'B5_Jun', 'CAB_May', 'GLCM_VV_dent_Jan', \n",
    "    'MCARI_Aug', 'Predicted_Height_A', 'TCARI_Jul', 'TCARI_Jun', 'sarRI2_Feb', 'sarSqDI_Sep'\n",
    "]\n",
    "target_variable = 'Dw_All_Mg'\n",
    "\n",
    "# Train the RandomForestRegressor model with specified hyperparameters\n",
    "model = RandomForestRegressor(n_estimators=100, max_features=10, random_state=7).fit(df[predictors], df[target_variable])\n",
    "\n",
    "# Extract feature importances from the model\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Create a DataFrame for easier viewing\n",
    "importances_df = pd.DataFrame({\n",
    "    'Feature': predictors,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance in descending order\n",
    "importances_df = importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the importances\n",
    "print(importances_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ebe8ce-0045-4ee3-b128-e201431c1f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "import warnings\n",
    "\n",
    "def predict_sd(input_image_path, model, predictors, output_folder_path, output_resolution=10):\n",
    "    with rasterio.open(input_image_path) as src:\n",
    "        # Adjust the transform for the output resolution if needed\n",
    "        transform = src.transform * src.transform.scale(\n",
    "            (src.width / src.width * output_resolution) / 10,\n",
    "            (src.height / src.height * output_resolution) / 10\n",
    "        )\n",
    "        \n",
    "        # Update metadata for the output raster, specifically for SD\n",
    "        meta = src.meta.copy()\n",
    "        meta.update(count=1, dtype='float32', transform=transform)\n",
    "        \n",
    "        sd_array = np.full((src.height, src.width), np.nan, dtype='float32')  # Initialize SD array\n",
    "        \n",
    "        for window in src.block_windows(1):\n",
    "            # Stack the required bands for prediction\n",
    "            data = np.stack([src.read(i+1, window=window[1], masked=True) for i, band in enumerate(src.descriptions) if band in predictors], axis=-1)\n",
    "            valid_mask = ~np.isnan(data).any(axis=-1)\n",
    "            \n",
    "            # Create a DataFrame for prediction to ensure feature names match\n",
    "            valid_data = pd.DataFrame(data[valid_mask].reshape(-1, len(predictors)), columns=predictors)\n",
    "            \n",
    "            if not valid_data.empty:\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\")\n",
    "                    # Predict using all trees to calculate SD\n",
    "                    all_predictions = np.stack([tree.predict(valid_data) for tree in model.estimators_], axis=0)\n",
    "                    sd = np.std(all_predictions, axis=0)  # Calculate SD\n",
    "                \n",
    "                # Fill the SD array\n",
    "                sd_array[window[1].row_off:window[1].row_off + window[1].height, window[1].col_off:window[1].col_off + window[1].width][valid_mask] = sd\n",
    "\n",
    "                \n",
    "        # Save the standard deviations as a single-band GeoTIFF\n",
    "        with rasterio.open(output_folder_path, 'w', **meta) as dst:\n",
    "            dst.write(sd_array, 1)\n",
    "            dst.set_band_description(1, 'AGB_Prediction_SD')\n",
    "\n",
    "# Set parameters for the prediction function\n",
    "input_image_path = r\"C:\\Uni\\EGM704\\GEE\\Exports\\Final Images\\Input_Raster.tif\"\n",
    "output_file_path = r\"C:\\...\\SD_Map.tif\"\n",
    "\n",
    "# Execute the prediction function to only produce and save the SD map\n",
    "predict_sd(input_image_path, model, predictors, output_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800f0824-a5b0-4dac-89f7-0cb136f615a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare with map of AGB\n",
    "\n",
    "def calculate_agb_statistics(agb_file_path, sd_file_path):\n",
    "    # Load the AGB map\n",
    "    with rasterio.open(agb_file_path) as agb_src:\n",
    "        agb_array = agb_src.read(1, masked=True)\n",
    "    \n",
    "    # Load the standard deviation (SD) map\n",
    "    with rasterio.open(sd_file_path) as sd_src:\n",
    "        sd_array = sd_src.read(1, masked=True)\n",
    "    \n",
    "    # Ensure that both arrays cover the same spatial extent and have the same dimensions\n",
    "    assert agb_array.shape == sd_array.shape, \"AGB and SD arrays must have the same dimensions\"\n",
    "    \n",
    "    # Calculate valid (non-NaN) values for AGB and SD\n",
    "    valid_agb = agb_array.compressed()  # Removes masked values, effectively ignoring NaNs\n",
    "    valid_sd = sd_array.compressed()\n",
    "    \n",
    "    # Calculate the average AGB\n",
    "    mean_agb = np.mean(valid_agb)\n",
    "    \n",
    "    # Calculate the average standard deviation (mean uncertainty)\n",
    "    mean_sd = np.mean(valid_sd)\n",
    "    \n",
    "    # Calculate the minimum and maximum standard deviation\n",
    "    min_sd = np.min(valid_sd)\n",
    "    max_sd = np.max(valid_sd)\n",
    "    \n",
    "    # Calculate the percentage of mean uncertainty with respect to mean predicted biomass\n",
    "    percentage_mean_uncertainty = (mean_sd / mean_agb) * 100\n",
    "    \n",
    "    # Print the statistics\n",
    "    print(f\"Average AGB: {mean_agb} Mg/ha\")\n",
    "    print(f\"Average SD (Uncertainty): {mean_sd} Mg/ha\")\n",
    "    print(f\"Minimum SD (Uncertainty): {min_sd} Mg/ha\")\n",
    "    print(f\"Maximum SD (Uncertainty): {max_sd} Mg/ha\")\n",
    "    print(f\"Range of SD (Uncertainty): {min_sd} to {max_sd} Mg/ha\")\n",
    "    print(f\"Percentage of Mean Uncertainty with respect to Mean Predicted Biomass: {percentage_mean_uncertainty}%\")\n",
    "\n",
    "# Paths to your AGB and SD files\n",
    "agb_file_path = r\"C:\\...\\Estimated_AGB_Map.tif\"\n",
    "sd_file_path = r\"C:\\...\\SD_Map.tif\"\n",
    "\n",
    "# Execute the function\n",
    "calculate_agb_statistics(agb_file_path, sd_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
